{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SLGL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWKs7S4PZR2b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "0fdc501d-0a8e-41f9-e84e-fd6bf72a30ec"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Aug  9 07:55:05 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTzcYrCvZuQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "!rm -r sample_data"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkB9zZRNbw9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clone repo AttnGAN\n",
        "os.chdir('/content/')\n",
        "!rm -r AttnGAN\n",
        "!git clone https://github.com/taoxugit/AttnGAN.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vj7VSMY-c6uI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download captionts filenames and classes info\n",
        "os.chdir('/content/AttnGAN/data/')\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ' -O birds.zip\n",
        "!unzip -q birds.zip\n",
        "!rm birds.zip\n",
        "!rm -r __MACOSX/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDk_GzlMduaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Changing Working dirctory to birds\n",
        "os.chdir('/content/AttnGAN/data/birds/')\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1hbzc_P1FuxMkcabkgn9ZKinBwW683j45' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1hbzc_P1FuxMkcabkgn9ZKinBwW683j45\" -O CUB_200_2011.tgz && rm -rf /tmp/cookies.txt\n",
        "!tar zxf  CUB_200_2011.tgz\n",
        "!rm CUB_200_2011.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r3rHv8ycCAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dwonload files text encoder and image encoder\n",
        "os.chdir('/content/AttnGAN/DAMSMencoders/')\n",
        "!rm -r bird/\n",
        "os.mkdir('bird')\n",
        "os.chdir('/content/')\n",
        "!git clone https://github.com/ammarnasr/CUB-Attn-GAN.git\n",
        "\n",
        "# #Move Models text and image encoder to their /content/\n",
        "!mv  /content/CUB-Attn-GAN/theModel/text_encoder599.pth  /content/AttnGAN/DAMSMencoders/bird/\n",
        "!mv /content/CUB-Attn-GAN/theModel/image_encoder599.pth /content/AttnGAN/DAMSMencoders/bird/\n",
        "\n",
        "!rm -r CUB-Attn-GAN "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDFg63INfn0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Download Pillow Font\n",
        "os.chdir('/content/AttnGAN/code/')\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Wr3lQajG7m6Bi3rYFTJb6mwE_d8su111' -O Pillow.rar\n",
        "!unrar x  Pillow.rar\n",
        "!rm Pillow.rar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gTLsxwtly4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Checkpoint from drive, edit in bird_attnGAN2.ymal also\n",
        "!cp '/content/drive/My Drive/ModifiedcubModelGAN/netG_epoch_50.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/ModifiedcubModelGAN/netD0.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/ModifiedcubModelGAN/netD1.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/ModifiedcubModelGAN/netD2.pth' '/content/AttnGAN/models/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESi47FqIgLlw",
        "colab_type": "text"
      },
      "source": [
        "# =============================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mTJmFZTgLPJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "f97e0b55-1dd0-408a-b0f6-d2963ca6310a"
      },
      "source": [
        "#Move code files to their Locations\n",
        "os.chdir('/content')\n",
        "!rm -r Modified_CUB_Attn_GAN/\n",
        "!git clone https://github.com/ammarnasr/SentLevelGANLoss.git\n",
        "\n",
        "!mv /content/SentLevelGANLoss/theCode/config.py                      /content/AttnGAN/code/miscc/\n",
        "!mv /content/SentLevelGANLoss/theCode/utils.py                      /content/AttnGAN/code/miscc/\n",
        "!mv /content/SentLevelGANLoss/theCode/datasets.py                  /content/AttnGAN/code/\n",
        "!mv /content/SentLevelGANLoss/theCode/GlobalAttention.py          /content/AttnGAN/code/\n",
        "!mv /content/SentLevelGANLoss/theCode/model.py                   /content/AttnGAN/code/\n",
        "!mv /content/SentLevelGANLoss/theCode/losses.py                 /content/AttnGAN/code/miscc/\n",
        "!mv /content/SentLevelGANLoss/theCode/trainer.py               /content/AttnGAN/code/\n",
        "!mv /content/SentLevelGANLoss/theCode/bird_attn2.yml          /content/AttnGAN/code/cfg/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'Modified_CUB_Attn_GAN/': No such file or directory\n",
            "Cloning into 'Modified_CUB_Attn_GAN'...\n",
            "remote: Enumerating objects: 76, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 76 (delta 22), reused 68 (delta 17), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (76/76), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btCJ5ibpf7rZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "df45326a-5fa7-4d2d-fde2-63f80a3192db"
      },
      "source": [
        "#run Code\n",
        "os.chdir('/content/AttnGAN/code/')\n",
        "!python main.py --cfg cfg/bird_attn2.yml --gpu 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using config:\n",
            "{'B_VALIDATION': False,\n",
            " 'CONFIG_NAME': 'attn2',\n",
            " 'CUDA': True,\n",
            " 'DATASET_NAME': 'birds',\n",
            " 'DATA_DIR': '../data/birds',\n",
            " 'GAN': {'B_ATTENTION': True,\n",
            "         'B_DCGAN': False,\n",
            "         'CONDITION_DIM': 100,\n",
            "         'DF_DIM': 64,\n",
            "         'GF_DIM': 32,\n",
            "         'R_NUM': 2,\n",
            "         'Z_DIM': 100},\n",
            " 'GPU_ID': 0,\n",
            " 'RNN_TYPE': 'LSTM',\n",
            " 'TEXT': {'CAPTIONS_PER_IMAGE': 10, 'EMBEDDING_DIM': 256, 'WORDS_NUM': 18},\n",
            " 'TRAIN': {'BATCH_SIZE': 20,\n",
            "           'B_NET_D': True,\n",
            "           'DISCRIMINATOR_LR': 0.0002,\n",
            "           'ENCODER_LR': 0.0002,\n",
            "           'FLAG': True,\n",
            "           'GENERATOR_LR': 0.0002,\n",
            "           'MAX_EPOCH': 600,\n",
            "           'NET_E': '../DAMSMencoders/bird/text_encoder599.pth',\n",
            "           'NET_G': '../models/netG_epoch_50.pth',\n",
            "           'RNN_GRAD_CLIP': 0.25,\n",
            "           'SMOOTH': {'GAMMA1': 4.0,\n",
            "                      'GAMMA2': 5.0,\n",
            "                      'GAMMA3': 10.0,\n",
            "                      'LAMBDA': 5.0},\n",
            "           'SNAPSHOT_INTERVAL': 10},\n",
            " 'TREE': {'BASE_SIZE': 64, 'BRANCH_NUM': 3},\n",
            " 'WORKERS': 4}\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:211: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions.pickle\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/checkpoints/inception_v3_google-1a9a5a14.pth\n",
            "100% 104M/104M [00:01<00:00, 80.4MB/s] \n",
            "Load pretrained model from  https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\n",
            "Load image encoder from: ../DAMSMencoders/bird/image_encoder599.pth\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Load text encoder from: ../DAMSMencoders/bird/text_encoder599.pth\n",
            "/content/AttnGAN/code/miscc/utils.py:404: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  nn.init.orthogonal(m.weight.data, 1.0)\n",
            "/content/AttnGAN/code/miscc/utils.py:399: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  nn.init.orthogonal(m.weight.data, 1.0)\n",
            "# of netsD 3\n",
            "Load G from:  ../models/netG_epoch_50.pth\n",
            "Load D from:  ../models/netD0.pth\n",
            "Load D from:  ../models/netD1.pth\n",
            "Load D from:  ../models/netD2.pth\n",
            "num_batches :  442\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/content/AttnGAN/code/GlobalAttention.py:116: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = self.sm(attn)  # Eq. (2)\n",
            "/content/AttnGAN/code/GlobalAttention.py:135: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  sent_att                = nn.Softmax()(sentence_vs)  # batch x idf x ih x iw\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/content/AttnGAN/code/GlobalAttention.py:51: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = nn.Softmax()(attn)  # Eq. (8)\n",
            "/content/AttnGAN/code/GlobalAttention.py:60: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = nn.Softmax()(attn)\n",
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n",
            "step :  100 iters_100_time :  72.35114455223083\n",
            "step :  200 iters_100_time :  68.23763489723206\n",
            "step :  300 iters_100_time :  68.27037501335144\n",
            "step :  400 iters_100_time :  68.30961489677429\n",
            "[51/600][442]\n",
            "                    Loss_D: 0.32 Loss_G: 46.17 Time: 305.97s\n",
            "num_batches :  442\n",
            "step :  500 iters_100_time :  40.31037640571594\n",
            "step :  600 iters_100_time :  68.36440849304199\n",
            "step :  700 iters_100_time :  68.31408548355103\n",
            "step :  800 iters_100_time :  68.24739265441895\n",
            "[52/600][442]\n",
            "                    Loss_D: 1.12 Loss_G: 41.32 Time: 302.72s\n",
            "num_batches :  442\n",
            "step :  900 iters_100_time :  11.662522792816162\n",
            "step :  1000 iters_100_time :  68.17619705200195\n",
            "step :  1100 iters_100_time :  68.16962218284607\n",
            "step :  1200 iters_100_time :  68.15844798088074\n",
            "step :  1300 iters_100_time :  68.18333148956299\n",
            "[53/600][442]\n",
            "                    Loss_D: 2.91 Loss_G: 63.23 Time: 302.35s\n",
            "num_batches :  442\n",
            "step :  1400 iters_100_time :  51.141414642333984\n",
            "step :  1500 iters_100_time :  68.30811738967896\n",
            "step :  1600 iters_100_time :  68.33771514892578\n",
            "step :  1700 iters_100_time :  68.28681492805481\n",
            "[54/600][442]\n",
            "                    Loss_D: 0.41 Loss_G: 47.74 Time: 302.69s\n",
            "num_batches :  442\n",
            "step :  1800 iters_100_time :  22.291751623153687\n",
            "step :  1900 iters_100_time :  68.25719857215881\n",
            "step :  2000 iters_100_time :  68.23525834083557\n",
            "step :  2100 iters_100_time :  68.2596492767334\n",
            "step :  2200 iters_100_time :  68.19654202461243\n",
            "[55/600][442]\n",
            "                    Loss_D: 0.83 Loss_G: 49.34 Time: 302.33s\n",
            "num_batches :  442\n",
            "step :  2300 iters_100_time :  61.90820837020874\n",
            "step :  2400 iters_100_time :  68.20069217681885\n",
            "step :  2500 iters_100_time :  68.26146483421326\n",
            "step :  2600 iters_100_time :  68.28714346885681\n",
            "[56/600][442]\n",
            "                    Loss_D: 1.76 Loss_G: 52.36 Time: 302.49s\n",
            "num_batches :  442\n",
            "step :  2700 iters_100_time :  33.43263053894043\n",
            "step :  2800 iters_100_time :  68.19371271133423\n",
            "step :  2900 iters_100_time :  68.28029036521912\n",
            "step :  3000 iters_100_time :  68.2810640335083\n",
            "[57/600][442]\n",
            "                    Loss_D: 0.08 Loss_G: 51.70 Time: 302.72s\n",
            "num_batches :  442\n",
            "step :  3100 iters_100_time :  4.750443696975708\n",
            "step :  3200 iters_100_time :  68.22603464126587\n",
            "step :  3300 iters_100_time :  68.34376621246338\n",
            "step :  3400 iters_100_time :  68.34682893753052\n",
            "step :  3500 iters_100_time :  68.33352255821228\n",
            "[58/600][442]\n",
            "                    Loss_D: 0.58 Loss_G: 36.51 Time: 302.83s\n",
            "num_batches :  442\n",
            "step :  3600 iters_100_time :  44.36260461807251\n",
            "step :  3700 iters_100_time :  68.2532548904419\n",
            "step :  3800 iters_100_time :  68.27537822723389\n",
            "step :  3900 iters_100_time :  68.36108231544495\n",
            "[59/600][442]\n",
            "                    Loss_D: 0.34 Loss_G: 57.08 Time: 302.90s\n",
            "num_batches :  442\n",
            "step :  4000 iters_100_time :  15.632317066192627\n",
            "step :  4100 iters_100_time :  68.29977798461914\n",
            "step :  4200 iters_100_time :  68.35678100585938\n",
            "step :  4300 iters_100_time :  68.41466188430786\n",
            "step :  4400 iters_100_time :  68.39024567604065\n",
            "[60/600][442]\n",
            "                    Loss_D: 1.24 Loss_G: 32.83 Time: 303.03s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  4500 iters_100_time :  55.47298765182495\n",
            "step :  4600 iters_100_time :  68.26924324035645\n",
            "step :  4700 iters_100_time :  68.32521772384644\n",
            "step :  4800 iters_100_time :  68.36339521408081\n",
            "[61/600][442]\n",
            "                    Loss_D: 0.48 Loss_G: 55.94 Time: 303.17s\n",
            "num_batches :  442\n",
            "step :  4900 iters_100_time :  26.570802927017212\n",
            "step :  5000 iters_100_time :  68.35408592224121\n",
            "step :  5000 iters_5000_time :  94.9249792098999\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  7.153627157211304\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  27.205130338668823\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  214.57588171958923\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "step :  5100 iters_100_time :  338.3045847415924\n",
            "step :  5200 iters_100_time :  68.33353805541992\n",
            "step :  5300 iters_100_time :  68.3842101097107\n",
            "[62/600][442]\n",
            "                    Loss_D: 0.79 Loss_G: 49.24 Time: 572.99s\n",
            "num_batches :  442\n",
            "step :  5400 iters_100_time :  66.13468909263611\n",
            "step :  5500 iters_100_time :  68.3303120136261\n",
            "step :  5600 iters_100_time :  68.26563310623169\n",
            "step :  5700 iters_100_time :  68.33005380630493\n",
            "[63/600][442]\n",
            "                    Loss_D: 1.25 Loss_G: 38.07 Time: 302.82s\n",
            "num_batches :  442\n",
            "step :  5800 iters_100_time :  37.54041075706482\n",
            "step :  5900 iters_100_time :  68.29568266868591\n",
            "step :  6000 iters_100_time :  68.33417892456055\n",
            "step :  6100 iters_100_time :  68.2949812412262\n",
            "[64/600][442]\n",
            "                    Loss_D: 0.38 Loss_G: 42.63 Time: 302.89s\n",
            "num_batches :  442\n",
            "step :  6200 iters_100_time :  8.793736219406128\n",
            "step :  6300 iters_100_time :  68.32320713996887\n",
            "step :  6400 iters_100_time :  68.40063047409058\n",
            "step :  6500 iters_100_time :  68.31284809112549\n",
            "step :  6600 iters_100_time :  68.39874243736267\n",
            "[65/600][442]\n",
            "                    Loss_D: 0.69 Loss_G: 35.98 Time: 303.11s\n",
            "num_batches :  442\n",
            "step :  6700 iters_100_time :  48.567548513412476\n",
            "step :  6800 iters_100_time :  68.34334135055542\n",
            "step :  6900 iters_100_time :  68.37659192085266\n",
            "step :  7000 iters_100_time :  68.31683993339539\n",
            "[66/600][442]\n",
            "                    Loss_D: 0.23 Loss_G: 48.19 Time: 303.15s\n",
            "num_batches :  442\n",
            "step :  7100 iters_100_time :  19.83606505393982\n",
            "step :  7200 iters_100_time :  68.37763571739197\n",
            "step :  7300 iters_100_time :  68.28759050369263\n",
            "step :  7400 iters_100_time :  68.36084914207458\n",
            "step :  7500 iters_100_time :  68.35620379447937\n",
            "[67/600][442]\n",
            "                    Loss_D: 0.57 Loss_G: 40.78 Time: 303.09s\n",
            "num_batches :  442\n",
            "step :  7600 iters_100_time :  59.39703035354614\n",
            "step :  7700 iters_100_time :  68.37516045570374\n",
            "step :  7800 iters_100_time :  68.37408423423767\n",
            "step :  7900 iters_100_time :  68.38305592536926\n",
            "[68/600][442]\n",
            "                    Loss_D: 1.23 Loss_G: 44.68 Time: 303.15s\n",
            "num_batches :  442\n",
            "step :  8000 iters_100_time :  30.773193836212158\n",
            "step :  8100 iters_100_time :  68.34406852722168\n",
            "step :  8200 iters_100_time :  68.42877721786499\n",
            "step :  8300 iters_100_time :  68.44811248779297\n",
            "[69/600][442]\n",
            "                    Loss_D: 0.25 Loss_G: 43.66 Time: 303.42s\n",
            "num_batches :  442\n",
            "step :  8400 iters_100_time :  2.142110586166382\n",
            "step :  8500 iters_100_time :  68.56516337394714\n",
            "step :  8600 iters_100_time :  68.35554456710815\n",
            "step :  8700 iters_100_time :  68.24021434783936\n",
            "step :  8800 iters_100_time :  68.31354451179504\n",
            "[70/600][442]\n",
            "                    Loss_D: 0.26 Loss_G: 52.09 Time: 303.22s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  8900 iters_100_time :  41.62269973754883\n",
            "step :  9000 iters_100_time :  68.21136546134949\n",
            "step :  9100 iters_100_time :  68.18396878242493\n",
            "step :  9200 iters_100_time :  68.15732598304749\n",
            "[71/600][442]\n",
            "                    Loss_D: 0.36 Loss_G: 41.74 Time: 302.45s\n",
            "num_batches :  442\n",
            "step :  9300 iters_100_time :  12.920414447784424\n",
            "step :  9400 iters_100_time :  68.22687339782715\n",
            "step :  9500 iters_100_time :  68.36156845092773\n",
            "step :  9600 iters_100_time :  68.28121590614319\n",
            "step :  9700 iters_100_time :  68.3398163318634\n",
            "[72/600][442]\n",
            "                    Loss_D: 0.99 Loss_G: 50.22 Time: 302.84s\n",
            "num_batches :  442\n",
            "step :  9800 iters_100_time :  52.46721839904785\n",
            "step :  9900 iters_100_time :  68.19981122016907\n",
            "step :  10000 iters_100_time :  68.3241057395935\n",
            "step :  10000 iters_5000_time :  188.99129176139832\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  6.915741920471191\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  26.508280277252197\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  207.07237100601196\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "step :  10100 iters_100_time :  329.92173075675964\n",
            "[73/600][442]\n",
            "                    Loss_D: 0.61 Loss_G: 58.45 Time: 564.40s\n",
            "num_batches :  442\n",
            "step :  10200 iters_100_time :  23.735065698623657\n",
            "step :  10300 iters_100_time :  68.44086503982544\n",
            "step :  10400 iters_100_time :  68.5267584323883\n",
            "step :  10500 iters_100_time :  68.4480938911438\n",
            "step :  10600 iters_100_time :  68.3798623085022\n",
            "[74/600][442]\n",
            "                    Loss_D: 0.29 Loss_G: 44.44 Time: 303.34s\n",
            "num_batches :  442\n",
            "step :  10700 iters_100_time :  63.70279312133789\n",
            "step :  10800 iters_100_time :  68.46100282669067\n",
            "step :  10900 iters_100_time :  68.45466303825378\n",
            "step :  11000 iters_100_time :  68.34547805786133\n",
            "[75/600][442]\n",
            "                    Loss_D: 2.98 Loss_G: 65.74 Time: 303.54s\n",
            "num_batches :  442\n",
            "step :  11100 iters_100_time :  34.76176142692566\n",
            "step :  11200 iters_100_time :  68.36424589157104\n",
            "step :  11300 iters_100_time :  68.26379752159119\n",
            "step :  11400 iters_100_time :  68.25576686859131\n",
            "[76/600][442]\n",
            "                    Loss_D: 1.42 Loss_G: 37.00 Time: 302.85s\n",
            "num_batches :  442\n",
            "step :  11500 iters_100_time :  6.095334768295288\n",
            "step :  11600 iters_100_time :  68.29255247116089\n",
            "step :  11700 iters_100_time :  68.32543015480042\n",
            "step :  11800 iters_100_time :  68.26627492904663\n",
            "step :  11900 iters_100_time :  68.22858381271362\n",
            "[77/600][442]\n",
            "                    Loss_D: 0.44 Loss_G: 48.58 Time: 302.76s\n",
            "num_batches :  442\n",
            "step :  12000 iters_100_time :  45.57708263397217\n",
            "step :  12100 iters_100_time :  68.18964624404907\n",
            "step :  12200 iters_100_time :  68.18720602989197\n",
            "step :  12300 iters_100_time :  68.249507188797\n",
            "[78/600][442]\n",
            "                    Loss_D: 0.18 Loss_G: 40.94 Time: 302.43s\n",
            "num_batches :  442\n",
            "step :  12400 iters_100_time :  16.983044147491455\n",
            "step :  12500 iters_100_time :  68.26114988327026\n",
            "step :  12600 iters_100_time :  68.27674603462219\n",
            "step :  12700 iters_100_time :  68.33206295967102\n",
            "step :  12800 iters_100_time :  68.27043414115906\n",
            "[79/600][442]\n",
            "                    Loss_D: 0.81 Loss_G: 52.21 Time: 302.77s\n",
            "num_batches :  442\n",
            "step :  12900 iters_100_time :  56.52211594581604\n",
            "step :  13000 iters_100_time :  68.28302693367004\n",
            "step :  13100 iters_100_time :  68.34417533874512\n",
            "step :  13200 iters_100_time :  68.24739003181458\n",
            "[80/600][442]\n",
            "                    Loss_D: 0.75 Loss_G: 51.39 Time: 302.72s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  13300 iters_100_time :  28.01709794998169\n",
            "step :  13400 iters_100_time :  68.19892525672913\n",
            "step :  13500 iters_100_time :  68.670565366745\n",
            "step :  13600 iters_100_time :  68.31452775001526\n",
            "step :  13700 iters_100_time :  68.16103601455688\n",
            "[81/600][442]\n",
            "                    Loss_D: 0.67 Loss_G: 46.65 Time: 303.16s\n",
            "num_batches :  442\n",
            "step :  13800 iters_100_time :  67.31196165084839\n",
            "step :  13900 iters_100_time :  68.22695255279541\n",
            "step :  14000 iters_100_time :  68.21027994155884\n",
            "step :  14100 iters_100_time :  68.2156913280487\n",
            "[82/600][442]\n",
            "                    Loss_D: 0.89 Loss_G: 62.13 Time: 302.41s\n",
            "num_batches :  442\n",
            "step :  14200 iters_100_time :  38.74728775024414\n",
            "step :  14300 iters_100_time :  68.22669982910156\n",
            "step :  14400 iters_100_time :  68.22037816047668\n",
            "step :  14500 iters_100_time :  68.25103402137756\n",
            "[83/600][442]\n",
            "                    Loss_D: 0.67 Loss_G: 37.84 Time: 302.50s\n",
            "num_batches :  442\n",
            "step :  14600 iters_100_time :  9.996713876724243\n",
            "step :  14700 iters_100_time :  68.24419283866882\n",
            "step :  14800 iters_100_time :  68.27953338623047\n",
            "step :  14900 iters_100_time :  68.30919790267944\n",
            "step :  15000 iters_100_time :  68.39036965370178\n",
            "step :  15000 iters_5000_time :  283.22023844718933\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  7.2736546993255615\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  27.79593276977539\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  214.9098925590515\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "[84/600][442]\n",
            "                    Loss_D: 0.14 Loss_G: 41.10 Time: 573.92s\n",
            "num_batches :  442\n",
            "step :  15100 iters_100_time :  49.88047003746033\n",
            "step :  15200 iters_100_time :  68.27396249771118\n",
            "step :  15300 iters_100_time :  68.28785705566406\n",
            "step :  15400 iters_100_time :  68.27774858474731\n",
            "[85/600][442]\n",
            "                    Loss_D: 0.19 Loss_G: 52.05 Time: 302.98s\n",
            "num_batches :  442\n",
            "step :  15500 iters_100_time :  21.080354928970337\n",
            "step :  15600 iters_100_time :  68.32593417167664\n",
            "step :  15700 iters_100_time :  68.34845614433289\n",
            "step :  15800 iters_100_time :  68.27584099769592\n",
            "step :  15900 iters_100_time :  68.28141856193542\n",
            "[86/600][442]\n",
            "                    Loss_D: 0.33 Loss_G: 40.22 Time: 302.92s\n",
            "num_batches :  442\n",
            "step :  16000 iters_100_time :  60.63726854324341\n",
            "step :  16100 iters_100_time :  68.25085616111755\n",
            "step :  16200 iters_100_time :  68.27464890480042\n",
            "step :  16300 iters_100_time :  68.32900381088257\n",
            "[87/600][442]\n",
            "                    Loss_D: 1.00 Loss_G: 42.29 Time: 302.75s\n",
            "num_batches :  442\n",
            "step :  16400 iters_100_time :  31.917943239212036\n",
            "step :  16500 iters_100_time :  68.22560501098633\n",
            "step :  16600 iters_100_time :  68.27054905891418\n",
            "step :  16700 iters_100_time :  68.27374958992004\n",
            "[88/600][442]\n",
            "                    Loss_D: 0.16 Loss_G: 45.32 Time: 302.61s\n",
            "num_batches :  442\n",
            "step :  16800 iters_100_time :  3.2921974658966064\n",
            "step :  16900 iters_100_time :  68.31996130943298\n",
            "step :  17000 iters_100_time :  68.3354914188385\n",
            "step :  17100 iters_100_time :  68.29289531707764\n",
            "step :  17200 iters_100_time :  68.26890587806702\n",
            "[89/600][442]\n",
            "                    Loss_D: 1.06 Loss_G: 48.67 Time: 302.86s\n",
            "num_batches :  442\n",
            "step :  17300 iters_100_time :  42.833553075790405\n",
            "step :  17400 iters_100_time :  68.297123670578\n",
            "step :  17500 iters_100_time :  68.31427049636841\n",
            "step :  17600 iters_100_time :  68.28963851928711\n",
            "[90/600][442]\n",
            "                    Loss_D: 0.17 Loss_G: 42.08 Time: 302.71s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  17700 iters_100_time :  14.40285849571228\n",
            "step :  17800 iters_100_time :  68.26594400405884\n",
            "step :  17900 iters_100_time :  68.35098838806152\n",
            "step :  18000 iters_100_time :  68.2922248840332\n",
            "step :  18100 iters_100_time :  68.36799836158752\n",
            "[91/600][442]\n",
            "                    Loss_D: 0.29 Loss_G: 52.88 Time: 303.15s\n",
            "num_batches :  442\n",
            "step :  18200 iters_100_time :  53.82383871078491\n",
            "step :  18300 iters_100_time :  68.33496141433716\n",
            "step :  18400 iters_100_time :  68.30494499206543\n",
            "step :  18500 iters_100_time :  68.2744619846344\n",
            "[92/600][442]\n",
            "                    Loss_D: 0.32 Loss_G: 50.36 Time: 302.85s\n",
            "num_batches :  442\n",
            "step :  18600 iters_100_time :  25.16853427886963\n",
            "step :  18700 iters_100_time :  68.32420945167542\n",
            "step :  18800 iters_100_time :  68.26892232894897\n",
            "step :  18900 iters_100_time :  68.3782422542572\n",
            "step :  19000 iters_100_time :  68.4421181678772\n",
            "[93/600][442]\n",
            "                    Loss_D: 1.38 Loss_G: 45.90 Time: 303.08s\n",
            "num_batches :  442\n",
            "step :  19100 iters_100_time :  65.20593690872192\n",
            "step :  19200 iters_100_time :  68.46739220619202\n",
            "step :  19300 iters_100_time :  68.27712082862854\n",
            "step :  19400 iters_100_time :  68.29619574546814\n",
            "[94/600][442]\n",
            "                    Loss_D: 0.41 Loss_G: 52.02 Time: 303.43s\n",
            "num_batches :  442\n",
            "step :  19500 iters_100_time :  36.14322876930237\n",
            "step :  19600 iters_100_time :  68.33524703979492\n",
            "step :  19700 iters_100_time :  68.39140939712524\n",
            "step :  19800 iters_100_time :  68.32484793663025\n",
            "[95/600][442]\n",
            "                    Loss_D: 2.02 Loss_G: 65.50 Time: 303.10s\n",
            "num_batches :  442\n",
            "step :  19900 iters_100_time :  7.444575786590576\n",
            "step :  20000 iters_100_time :  68.24171161651611\n",
            "step :  20000 iters_5000_time :  75.68638563156128\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  6.897245645523071\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  26.447498321533203\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  205.6981077194214\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "step :  20100 iters_100_time :  327.345965385437\n",
            "step :  20200 iters_100_time :  68.27045822143555\n",
            "step :  20300 iters_100_time :  68.270911693573\n",
            "[96/600][442]\n",
            "                    Loss_D: 0.47 Loss_G: 47.10 Time: 561.79s\n",
            "num_batches :  442\n",
            "step :  20400 iters_100_time :  46.86229944229126\n",
            "step :  20500 iters_100_time :  68.24493885040283\n",
            "step :  20600 iters_100_time :  68.28501319885254\n",
            "step :  20700 iters_100_time :  68.33770895004272\n",
            "[97/600][442]\n",
            "                    Loss_D: 0.43 Loss_G: 54.76 Time: 302.79s\n",
            "num_batches :  442\n",
            "step :  20800 iters_100_time :  18.36531972885132\n",
            "step :  20900 iters_100_time :  68.36865139007568\n",
            "step :  21000 iters_100_time :  68.41669607162476\n",
            "step :  21100 iters_100_time :  68.40472412109375\n",
            "step :  21200 iters_100_time :  68.35824775695801\n",
            "[98/600][442]\n",
            "                    Loss_D: 1.49 Loss_G: 37.91 Time: 303.26s\n",
            "num_batches :  442\n",
            "step :  21300 iters_100_time :  57.97051978111267\n",
            "step :  21400 iters_100_time :  68.3558931350708\n",
            "step :  21500 iters_100_time :  68.3720395565033\n",
            "step :  21600 iters_100_time :  68.40589499473572\n",
            "[99/600][442]\n",
            "                    Loss_D: 0.74 Loss_G: 61.39 Time: 303.14s\n",
            "num_batches :  442\n",
            "step :  21700 iters_100_time :  29.257123231887817\n",
            "step :  21800 iters_100_time :  68.37977719306946\n",
            "step :  21900 iters_100_time :  68.4046618938446\n",
            "step :  22000 iters_100_time :  68.38957905769348\n",
            "step :  22100 iters_100_time :  68.32883787155151\n",
            "[100/600][442]\n",
            "                    Loss_D: 0.44 Loss_G: 49.48 Time: 303.21s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  22200 iters_100_time :  68.94545292854309\n",
            "step :  22300 iters_100_time :  68.30811762809753\n",
            "step :  22400 iters_100_time :  68.2652370929718\n",
            "step :  22500 iters_100_time :  68.22753405570984\n",
            "[101/600][442]\n",
            "                    Loss_D: 0.10 Loss_G: 56.55 Time: 302.84s\n",
            "num_batches :  442\n",
            "step :  22600 iters_100_time :  40.25079822540283\n",
            "step :  22700 iters_100_time :  68.4414336681366\n",
            "step :  22800 iters_100_time :  68.37469744682312\n",
            "step :  22900 iters_100_time :  68.41799592971802\n",
            "[102/600][442]\n",
            "                    Loss_D: 0.29 Loss_G: 41.07 Time: 303.29s\n",
            "num_batches :  442\n",
            "step :  23000 iters_100_time :  11.448310375213623\n",
            "step :  23100 iters_100_time :  68.309330701828\n",
            "step :  23200 iters_100_time :  68.41251516342163\n",
            "step :  23300 iters_100_time :  68.36440682411194\n",
            "step :  23400 iters_100_time :  68.39352440834045\n",
            "[103/600][442]\n",
            "                    Loss_D: 0.81 Loss_G: 47.57 Time: 303.14s\n",
            "num_batches :  442\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU78aNl1gQdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}