{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SLGL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWKs7S4PZR2b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "9b3e08c1-5347-4e67-aada-cde63266bce9"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Aug 18 21:20:19 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTzcYrCvZuQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "!rm -r sample_data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkB9zZRNbw9N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "02dd5a8f-f8a3-4a3a-d207-bab2daf703d6"
      },
      "source": [
        "#clone repo AttnGAN\n",
        "os.chdir('/content/')\n",
        "!rm -r AttnGAN\n",
        "!git clone https://github.com/taoxugit/AttnGAN.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'AttnGAN': No such file or directory\n",
            "Cloning into 'AttnGAN'...\n",
            "remote: Enumerating objects: 291, done.\u001b[K\n",
            "remote: Total 291 (delta 0), reused 0 (delta 0), pack-reused 291\u001b[K\n",
            "Receiving objects: 100% (291/291), 36.76 MiB | 38.52 MiB/s, done.\n",
            "Resolving deltas: 100% (167/167), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vj7VSMY-c6uI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "916d363e-058d-41e5-a643-3f9457ddb425"
      },
      "source": [
        "# Download captionts filenames and classes info\n",
        "os.chdir('/content/AttnGAN/data/')\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ' -O birds.zip\n",
        "!unzip -q birds.zip\n",
        "!rm birds.zip\n",
        "!rm -r __MACOSX/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-18 21:21:32--  https://docs.google.com/uc?export=download&id=1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.20.113, 74.125.20.101, 74.125.20.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.20.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0o-9g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/pmt500hj469c98ijcsjgu4g5qrl94t8n/1597785675000/09657060183789739732/*/1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-08-18 21:22:02--  https://doc-0o-9g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/pmt500hj469c98ijcsjgu4g5qrl94t8n/1597785675000/09657060183789739732/*/1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ?e=download\n",
            "Resolving doc-0o-9g-docs.googleusercontent.com (doc-0o-9g-docs.googleusercontent.com)... 74.125.142.132, 2607:f8b0:400e:c08::84\n",
            "Connecting to doc-0o-9g-docs.googleusercontent.com (doc-0o-9g-docs.googleusercontent.com)|74.125.142.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘birds.zip’\n",
            "\n",
            "birds.zip               [ <=>                ]   6.19M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-08-18 21:22:02 (134 MB/s) - ‘birds.zip’ saved [6488322]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDk_GzlMduaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Changing Working dirctory to birds\n",
        "os.chdir('/content/AttnGAN/data/birds/')\n",
        "!cp '/content/drive/My Drive/cub/CUB_200_2011.tgz' '/content/AttnGAN/data/birds/'\n",
        "!tar zxf  CUB_200_2011.tgz\n",
        "!rm CUB_200_2011.tgz"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r3rHv8ycCAS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "8c446277-d6af-4b2f-fb7d-09e30ab358d5"
      },
      "source": [
        "#Dwonload files text encoder and image encoder\n",
        "os.chdir('/content/AttnGAN/DAMSMencoders/')\n",
        "!rm -r bird/\n",
        "os.mkdir('bird')\n",
        "os.chdir('/content/')\n",
        "!git clone https://github.com/ammarnasr/CUB-Attn-GAN.git\n",
        "\n",
        "# #Move Models text and image encoder to their /content/\n",
        "!mv  /content/CUB-Attn-GAN/theModel/text_encoder599.pth  /content/AttnGAN/DAMSMencoders/bird/\n",
        "!mv /content/CUB-Attn-GAN/theModel/image_encoder599.pth /content/AttnGAN/DAMSMencoders/bird/\n",
        "\n",
        "!rm -r CUB-Attn-GAN "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'bird/': No such file or directory\n",
            "Cloning into 'CUB-Attn-GAN'...\n",
            "remote: Enumerating objects: 292, done.\u001b[K\n",
            "remote: Counting objects: 100% (292/292), done.\u001b[K\n",
            "remote: Compressing objects: 100% (187/187), done.\u001b[K\n",
            "remote: Total 842 (delta 197), reused 193 (delta 103), pack-reused 550\u001b[K\n",
            "Receiving objects: 100% (842/842), 475.00 MiB | 37.90 MiB/s, done.\n",
            "Resolving deltas: 100% (497/497), done.\n",
            "Checking out files: 100% (117/117), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDFg63INfn0O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "8904f913-f59f-4c9c-88b3-45983dfb818a"
      },
      "source": [
        "#Download Pillow Font\n",
        "os.chdir('/content/AttnGAN/code/')\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Wr3lQajG7m6Bi3rYFTJb6mwE_d8su111' -O Pillow.rar\n",
        "!unrar x  Pillow.rar\n",
        "!rm Pillow.rar"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-18 21:23:57--  https://docs.google.com/uc?export=download&id=1Wr3lQajG7m6Bi3rYFTJb6mwE_d8su111\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.197.100, 74.125.197.138, 74.125.197.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.197.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-04-6c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/te2mju8h3ltfvlv4cr3cpc4trtllblpt/1597785825000/17309505201871794426/*/1Wr3lQajG7m6Bi3rYFTJb6mwE_d8su111?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-08-18 21:23:58--  https://doc-04-6c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/te2mju8h3ltfvlv4cr3cpc4trtllblpt/1597785825000/17309505201871794426/*/1Wr3lQajG7m6Bi3rYFTJb6mwE_d8su111?e=download\n",
            "Resolving doc-04-6c-docs.googleusercontent.com (doc-04-6c-docs.googleusercontent.com)... 74.125.142.132, 2607:f8b0:400e:c08::84\n",
            "Connecting to doc-04-6c-docs.googleusercontent.com (doc-04-6c-docs.googleusercontent.com)|74.125.142.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 257793 (252K) [application/x-rar]\n",
            "Saving to: ‘Pillow.rar’\n",
            "\n",
            "\rPillow.rar            0%[                    ]       0  --.-KB/s               \rPillow.rar          100%[===================>] 251.75K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2020-08-18 21:23:58 (151 MB/s) - ‘Pillow.rar’ saved [257793/257793]\n",
            "\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from Pillow.rar\n",
            "\n",
            "Creating    Pillow                                                    OK\n",
            "Creating    Pillow/Tests                                              OK\n",
            "Creating    Pillow/Tests/fonts                                        OK\n",
            "Extracting  Pillow/Tests/fonts/FreeMono.ttf                              \b\b\b\b 12%\b\b\b\b 25%\b\b\b\b 38%\b\b\b\b 50%\b\b\b\b 63%\b\b\b\b 76%\b\b\b\b 88%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gTLsxwtly4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Checkpoint from drive, edit in bird_attnGAN2.ymal also\n",
        "!cp '/content/drive/My Drive/ModifiedcubModelGAN/netG_epoch_570.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/ModifiedcubModelGAN/netD0.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/ModifiedcubModelGAN/netD1.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/ModifiedcubModelGAN/netD2.pth' '/content/AttnGAN/models/'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESi47FqIgLlw",
        "colab_type": "text"
      },
      "source": [
        "# =============================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mTJmFZTgLPJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "b782990f-1065-4070-b8f2-32ba995b4470"
      },
      "source": [
        "#Move code files to their Locations\n",
        "os.chdir('/content')\n",
        "!rm -r SentLevelGANLoss/\n",
        "!git clone https://github.com/ammarnasr/SentLevelGANLoss.git\n",
        "\n",
        "!mv /content/SentLevelGANLoss/theCode/config.py                      /content/AttnGAN/code/miscc/\n",
        "!mv /content/SentLevelGANLoss/theCode/utils.py                      /content/AttnGAN/code/miscc/\n",
        "!mv /content/SentLevelGANLoss/theCode/datasets.py                  /content/AttnGAN/code/\n",
        "!mv /content/SentLevelGANLoss/theCode/GlobalAttention.py          /content/AttnGAN/code/\n",
        "!mv /content/SentLevelGANLoss/theCode/model.py                   /content/AttnGAN/code/\n",
        "!mv /content/SentLevelGANLoss/theCode/losses.py                 /content/AttnGAN/code/miscc/\n",
        "!mv /content/SentLevelGANLoss/theCode/trainer.py               /content/AttnGAN/code/\n",
        "!mv /content/SentLevelGANLoss/theCode/bird_attn2.yml          /content/AttnGAN/code/cfg/"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'SentLevelGANLoss/': No such file or directory\n",
            "Cloning into 'SentLevelGANLoss'...\n",
            "remote: Enumerating objects: 126, done.\u001b[K\n",
            "remote: Counting objects: 100% (126/126), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 126 (delta 53), reused 112 (delta 42), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (126/126), 884.30 KiB | 6.85 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btCJ5ibpf7rZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e913d8b7-bf63-4447-f7f6-f3034ecac492"
      },
      "source": [
        "#run Code\n",
        "os.chdir('/content/AttnGAN/code/')\n",
        "!python main.py --cfg cfg/bird_attn2.yml --gpu 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using config:\n",
            "{'B_VALIDATION': False,\n",
            " 'CONFIG_NAME': 'attn2',\n",
            " 'CUDA': True,\n",
            " 'DATASET_NAME': 'birds',\n",
            " 'DATA_DIR': '../data/birds',\n",
            " 'GAN': {'B_ATTENTION': True,\n",
            "         'B_DCGAN': False,\n",
            "         'CONDITION_DIM': 100,\n",
            "         'DF_DIM': 64,\n",
            "         'GF_DIM': 32,\n",
            "         'R_NUM': 2,\n",
            "         'Z_DIM': 100},\n",
            " 'GPU_ID': 0,\n",
            " 'RNN_TYPE': 'LSTM',\n",
            " 'TEXT': {'CAPTIONS_PER_IMAGE': 10, 'EMBEDDING_DIM': 256, 'WORDS_NUM': 18},\n",
            " 'TRAIN': {'BATCH_SIZE': 20,\n",
            "           'B_NET_D': True,\n",
            "           'DISCRIMINATOR_LR': 0.0002,\n",
            "           'ENCODER_LR': 0.0002,\n",
            "           'FLAG': True,\n",
            "           'GENERATOR_LR': 0.0002,\n",
            "           'MAX_EPOCH': 600,\n",
            "           'NET_E': '../DAMSMencoders/bird/text_encoder599.pth',\n",
            "           'NET_G': '../models/netG_epoch_530.pth',\n",
            "           'RNN_GRAD_CLIP': 0.25,\n",
            "           'SMOOTH': {'GAMMA1': 4.0,\n",
            "                      'GAMMA2': 5.0,\n",
            "                      'GAMMA3': 10.0,\n",
            "                      'LAMBDA': 5.0},\n",
            "           'SNAPSHOT_INTERVAL': 10},\n",
            " 'TREE': {'BASE_SIZE': 64, 'BRANCH_NUM': 3},\n",
            " 'WORKERS': 4}\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:257: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions.pickle\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/models/inception.py:77: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-1a9a5a14.pth\n",
            "100% 104M/104M [00:02<00:00, 50.4MB/s]\n",
            "Load pretrained model from  https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\n",
            "Load image encoder from: ../DAMSMencoders/bird/image_encoder599.pth\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Load text encoder from: ../DAMSMencoders/bird/text_encoder599.pth\n",
            "/content/AttnGAN/code/miscc/utils.py:404: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  nn.init.orthogonal(m.weight.data, 1.0)\n",
            "/content/AttnGAN/code/miscc/utils.py:399: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  nn.init.orthogonal(m.weight.data, 1.0)\n",
            "# of netsD 3\n",
            "Load G from:  ../models/netG_epoch_530.pth\n",
            "Load D from:  ../models/netD0.pth\n",
            "Load D from:  ../models/netD1.pth\n",
            "Load D from:  ../models/netD2.pth\n",
            "START EPOCH IS =========  531\n",
            "num_batches :  442\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/content/AttnGAN/code/GlobalAttention.py:116: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = self.sm(attn)  # Eq. (2)\n",
            "/content/AttnGAN/code/GlobalAttention.py:135: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  sent_att                = nn.Softmax()(sentence_vs)  # batch x idf x ih x iw\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/content/AttnGAN/code/GlobalAttention.py:51: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = nn.Softmax()(attn)  # Eq. (8)\n",
            "/content/AttnGAN/code/GlobalAttention.py:60: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = nn.Softmax()(attn)\n",
            "[W TensorIterator.cpp:918] Warning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (function operator())\n",
            "/content/AttnGAN/code/trainer.py:428: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
            "  avg_p.mul_(0.999).add_(0.001, p.data)\n",
            "step :  100 iters_100_time :  128.4032700061798\n",
            "step :  200 iters_100_time :  124.23803186416626\n",
            "step :  300 iters_100_time :  124.59483790397644\n",
            "step :  400 iters_100_time :  123.62489461898804\n",
            "[531/600][442]\n",
            "                    Loss_D: 0.02 Loss_G: 57.26 Time: 553.13s\n",
            "num_batches :  442\n",
            "step :  500 iters_100_time :  72.78257536888123\n",
            "step :  600 iters_100_time :  124.48239064216614\n",
            "step :  700 iters_100_time :  124.33823752403259\n",
            "step :  800 iters_100_time :  124.45963168144226\n",
            "[532/600][442]\n",
            "                    Loss_D: 0.44 Loss_G: 61.97 Time: 550.60s\n",
            "num_batches :  442\n",
            "step :  900 iters_100_time :  20.627309799194336\n",
            "step :  1000 iters_100_time :  124.45613884925842\n",
            "step :  1100 iters_100_time :  124.21329259872437\n",
            "step :  1200 iters_100_time :  124.51588082313538\n",
            "step :  1300 iters_100_time :  124.16871881484985\n",
            "[533/600][442]\n",
            "                    Loss_D: 0.06 Loss_G: 62.76 Time: 551.37s\n",
            "num_batches :  442\n",
            "step :  1400 iters_100_time :  92.31313610076904\n",
            "step :  1500 iters_100_time :  123.8281421661377\n",
            "step :  1600 iters_100_time :  124.8798234462738\n",
            "step :  1700 iters_100_time :  124.15834403038025\n",
            "[534/600][442]\n",
            "                    Loss_D: 0.03 Loss_G: 83.96 Time: 549.85s\n",
            "num_batches :  442\n",
            "step :  1800 iters_100_time :  40.1618070602417\n",
            "step :  1900 iters_100_time :  124.62950205802917\n",
            "step :  2000 iters_100_time :  124.23485493659973\n",
            "step :  2100 iters_100_time :  124.69194531440735\n",
            "step :  2200 iters_100_time :  123.88166666030884\n",
            "[535/600][442]\n",
            "                    Loss_D: 0.08 Loss_G: 72.08 Time: 550.62s\n",
            "num_batches :  442\n",
            "step :  2300 iters_100_time :  112.22762537002563\n",
            "step :  2400 iters_100_time :  124.76231074333191\n",
            "step :  2500 iters_100_time :  123.96212887763977\n",
            "step :  2600 iters_100_time :  124.38130450248718\n",
            "[536/600][442]\n",
            "                    Loss_D: 0.20 Loss_G: 59.71 Time: 550.26s\n",
            "num_batches :  442\n",
            "step :  2700 iters_100_time :  59.77238440513611\n",
            "step :  2800 iters_100_time :  124.7007884979248\n",
            "step :  2900 iters_100_time :  123.75950264930725\n",
            "step :  3000 iters_100_time :  124.51235580444336\n",
            "[537/600][442]\n",
            "                    Loss_D: 0.05 Loss_G: 49.20 Time: 550.03s\n",
            "num_batches :  442\n",
            "step :  3100 iters_100_time :  7.9883482456207275\n",
            "step :  3200 iters_100_time :  123.92964005470276\n",
            "step :  3300 iters_100_time :  123.48314237594604\n",
            "step :  3400 iters_100_time :  125.05113053321838\n",
            "step :  3500 iters_100_time :  123.89693927764893\n",
            "[538/600][442]\n",
            "                    Loss_D: 0.08 Loss_G: 73.94 Time: 549.27s\n",
            "num_batches :  442\n",
            "step :  3600 iters_100_time :  79.9995493888855\n",
            "step :  3700 iters_100_time :  124.45294308662415\n",
            "step :  3800 iters_100_time :  124.56356024742126\n",
            "step :  3900 iters_100_time :  124.41934204101562\n",
            "[539/600][442]\n",
            "                    Loss_D: 0.33 Loss_G: 50.67 Time: 550.05s\n",
            "num_batches :  442\n",
            "step :  4000 iters_100_time :  27.63217282295227\n",
            "step :  4100 iters_100_time :  124.75756525993347\n",
            "step :  4200 iters_100_time :  124.38719248771667\n",
            "step :  4300 iters_100_time :  124.11118936538696\n",
            "step :  4400 iters_100_time :  124.71287178993225\n",
            "[540/600][442]\n",
            "                    Loss_D: 0.37 Loss_G: 43.32 Time: 551.17s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  4500 iters_100_time :  99.78775954246521\n",
            "step :  4600 iters_100_time :  124.93256139755249\n",
            "step :  4700 iters_100_time :  124.14951539039612\n",
            "step :  4800 iters_100_time :  124.8420193195343\n",
            "[541/600][442]\n",
            "                    Loss_D: 0.71 Loss_G: 37.93 Time: 550.81s\n",
            "num_batches :  442\n",
            "step :  4900 iters_100_time :  48.03266787528992\n",
            "step :  5000 iters_100_time :  124.17687654495239\n",
            "step :  5100 iters_100_time :  125.13469386100769\n",
            "step :  5200 iters_100_time :  124.53157329559326\n",
            "step :  5300 iters_100_time :  124.62124681472778\n",
            "[542/600][442]\n",
            "                    Loss_D: 0.08 Loss_G: 63.55 Time: 551.80s\n",
            "num_batches :  442\n",
            "step :  5400 iters_100_time :  119.67089581489563\n",
            "step :  5500 iters_100_time :  124.89128804206848\n",
            "step :  5600 iters_100_time :  124.76749157905579\n",
            "step :  5700 iters_100_time :  123.84864234924316\n",
            "[543/600][442]\n",
            "                    Loss_D: 0.38 Loss_G: 50.98 Time: 550.76s\n",
            "num_batches :  442\n",
            "step :  5800 iters_100_time :  67.2478232383728\n",
            "step :  5900 iters_100_time :  123.79099822044373\n",
            "step :  6000 iters_100_time :  124.20709705352783\n",
            "step :  6100 iters_100_time :  123.75194215774536\n",
            "[544/600][442]\n",
            "                    Loss_D: 0.37 Loss_G: 55.37 Time: 547.95s\n",
            "num_batches :  442\n",
            "step :  6200 iters_100_time :  15.554651737213135\n",
            "step :  6300 iters_100_time :  124.17436099052429\n",
            "step :  6400 iters_100_time :  123.12470769882202\n",
            "step :  6500 iters_100_time :  124.12204098701477\n",
            "step :  6600 iters_100_time :  123.97666215896606\n",
            "[545/600][442]\n",
            "                    Loss_D: 1.03 Loss_G: 78.61 Time: 548.53s\n",
            "num_batches :  442\n",
            "step :  6700 iters_100_time :  87.47274112701416\n",
            "step :  6800 iters_100_time :  124.23480939865112\n",
            "step :  6900 iters_100_time :  123.80209016799927\n",
            "step :  7000 iters_100_time :  124.97594928741455\n",
            "[546/600][442]\n",
            "                    Loss_D: 0.13 Loss_G: 56.74 Time: 549.21s\n",
            "num_batches :  442\n",
            "step :  7100 iters_100_time :  35.05215263366699\n",
            "step :  7200 iters_100_time :  124.43990659713745\n",
            "step :  7300 iters_100_time :  123.17388319969177\n",
            "step :  7400 iters_100_time :  124.37216448783875\n",
            "step :  7500 iters_100_time :  124.06400799751282\n",
            "[547/600][442]\n",
            "                    Loss_D: 0.07 Loss_G: 62.08 Time: 548.50s\n",
            "num_batches :  442\n",
            "step :  7600 iters_100_time :  107.12650084495544\n",
            "step :  7700 iters_100_time :  124.00332617759705\n",
            "step :  7800 iters_100_time :  123.83887648582458\n",
            "step :  7900 iters_100_time :  123.66765308380127\n",
            "[548/600][442]\n",
            "                    Loss_D: 0.05 Loss_G: 65.36 Time: 548.10s\n",
            "num_batches :  442\n",
            "step :  8000 iters_100_time :  54.4879150390625\n",
            "step :  8100 iters_100_time :  124.0600380897522\n",
            "step :  8200 iters_100_time :  123.39312791824341\n",
            "step :  8300 iters_100_time :  124.37496876716614\n",
            "[549/600][442]\n",
            "                    Loss_D: 0.70 Loss_G: 52.22 Time: 548.50s\n",
            "num_batches :  442\n",
            "step :  8400 iters_100_time :  3.062264919281006\n",
            "step :  8500 iters_100_time :  123.96710419654846\n",
            "step :  8600 iters_100_time :  123.89618444442749\n",
            "step :  8700 iters_100_time :  123.78343367576599\n",
            "step :  8800 iters_100_time :  123.64026236534119\n",
            "[550/600][442]\n",
            "                    Loss_D: 0.07 Loss_G: 60.91 Time: 548.16s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  8900 iters_100_time :  74.66820001602173\n",
            "step :  9000 iters_100_time :  123.07380366325378\n",
            "step :  9100 iters_100_time :  123.74404621124268\n",
            "step :  9200 iters_100_time :  123.57693719863892\n",
            "[551/600][442]\n",
            "                    Loss_D: 0.05 Loss_G: 62.75 Time: 546.11s\n",
            "num_batches :  442\n",
            "step :  9300 iters_100_time :  22.80182147026062\n",
            "step :  9400 iters_100_time :  123.05403280258179\n",
            "step :  9500 iters_100_time :  123.59355449676514\n",
            "step :  9600 iters_100_time :  123.16350626945496\n",
            "step :  9700 iters_100_time :  122.87698030471802\n",
            "[552/600][442]\n",
            "                    Loss_D: 0.22 Loss_G: 64.92 Time: 545.46s\n",
            "num_batches :  442\n",
            "step :  9800 iters_100_time :  94.10860252380371\n",
            "step :  9900 iters_100_time :  122.80072379112244\n",
            "step :  10000 iters_100_time :  123.2195839881897\n",
            "step :  10100 iters_100_time :  123.757159948349\n",
            "[553/600][442]\n",
            "                    Loss_D: 0.06 Loss_G: 61.54 Time: 545.02s\n",
            "num_batches :  442\n",
            "step :  10200 iters_100_time :  42.61022448539734\n",
            "step :  10300 iters_100_time :  123.37032794952393\n",
            "step :  10400 iters_100_time :  123.25680470466614\n",
            "step :  10500 iters_100_time :  123.23554468154907\n",
            "step :  10600 iters_100_time :  123.04270339012146\n",
            "[554/600][442]\n",
            "                    Loss_D: 0.13 Loss_G: 52.96 Time: 545.70s\n",
            "num_batches :  442\n",
            "step :  10700 iters_100_time :  113.92508172988892\n",
            "step :  10800 iters_100_time :  123.46574401855469\n",
            "step :  10900 iters_100_time :  122.98035788536072\n",
            "step :  11000 iters_100_time :  123.7995080947876\n",
            "[555/600][442]\n",
            "                    Loss_D: 0.13 Loss_G: 57.10 Time: 545.76s\n",
            "num_batches :  442\n",
            "step :  11100 iters_100_time :  61.71713995933533\n",
            "step :  11200 iters_100_time :  123.91730499267578\n",
            "step :  11300 iters_100_time :  123.14918756484985\n",
            "step :  11400 iters_100_time :  123.6237301826477\n",
            "[556/600][442]\n",
            "                    Loss_D: 0.29 Loss_G: 61.21 Time: 545.73s\n",
            "num_batches :  442\n",
            "step :  11500 iters_100_time :  10.162259101867676\n",
            "step :  11600 iters_100_time :  123.52547311782837\n",
            "step :  11700 iters_100_time :  123.1837854385376\n",
            "step :  11800 iters_100_time :  122.85550308227539\n",
            "step :  11900 iters_100_time :  123.87981343269348\n",
            "[557/600][442]\n",
            "                    Loss_D: 0.16 Loss_G: 65.42 Time: 545.79s\n",
            "num_batches :  442\n",
            "step :  12000 iters_100_time :  81.67089605331421\n",
            "step :  12100 iters_100_time :  123.71563386917114\n",
            "step :  12200 iters_100_time :  122.976309299469\n",
            "step :  12300 iters_100_time :  123.8939139842987\n",
            "[558/600][442]\n",
            "                    Loss_D: 0.05 Loss_G: 72.88 Time: 547.15s\n",
            "num_batches :  442\n",
            "step :  12400 iters_100_time :  30.394716501235962\n",
            "step :  12500 iters_100_time :  123.5253791809082\n",
            "step :  12600 iters_100_time :  123.9955666065216\n",
            "step :  12700 iters_100_time :  123.52836179733276\n",
            "step :  12800 iters_100_time :  123.80210638046265\n",
            "[559/600][442]\n",
            "                    Loss_D: 0.28 Loss_G: 54.50 Time: 548.29s\n",
            "num_batches :  442\n",
            "step :  12900 iters_100_time :  101.73492121696472\n",
            "step :  13000 iters_100_time :  124.13125085830688\n",
            "step :  13100 iters_100_time :  122.93212652206421\n",
            "step :  13200 iters_100_time :  123.56260061264038\n",
            "[560/600][442]\n",
            "                    Loss_D: 0.17 Loss_G: 73.81 Time: 547.27s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  13300 iters_100_time :  49.70138883590698\n",
            "step :  13400 iters_100_time :  123.871652841568\n",
            "step :  13500 iters_100_time :  123.94757032394409\n",
            "step :  13600 iters_100_time :  123.36013388633728\n",
            "step :  13700 iters_100_time :  123.26226782798767\n",
            "[561/600][442]\n",
            "                    Loss_D: 0.01 Loss_G: 70.90 Time: 546.92s\n",
            "num_batches :  442\n",
            "step :  13800 iters_100_time :  122.24738383293152\n",
            "step :  13900 iters_100_time :  123.0192859172821\n",
            "step :  14000 iters_100_time :  123.45677518844604\n",
            "step :  14100 iters_100_time :  124.44905757904053\n",
            "[562/600][442]\n",
            "                    Loss_D: 0.07 Loss_G: 55.07 Time: 547.73s\n",
            "num_batches :  442\n",
            "step :  14200 iters_100_time :  69.91007971763611\n",
            "step :  14300 iters_100_time :  124.88641381263733\n",
            "step :  14400 iters_100_time :  122.96027278900146\n",
            "step :  14500 iters_100_time :  123.82120704650879\n",
            "[563/600][442]\n",
            "                    Loss_D: 0.10 Loss_G: 74.51 Time: 549.24s\n",
            "num_batches :  442\n",
            "step :  14600 iters_100_time :  17.78351879119873\n",
            "step :  14700 iters_100_time :  124.51955199241638\n",
            "step :  14800 iters_100_time :  124.47885537147522\n",
            "step :  14900 iters_100_time :  124.20146250724792\n",
            "step :  15000 iters_100_time :  124.10606598854065\n",
            "[564/600][442]\n",
            "                    Loss_D: 1.42 Loss_G: 48.15 Time: 550.04s\n",
            "num_batches :  442\n",
            "step :  15100 iters_100_time :  89.57471990585327\n",
            "step :  15200 iters_100_time :  123.7643883228302\n",
            "step :  15300 iters_100_time :  123.65523529052734\n",
            "step :  15400 iters_100_time :  123.23530530929565\n",
            "[565/600][442]\n",
            "                    Loss_D: 0.32 Loss_G: 71.53 Time: 547.12s\n",
            "num_batches :  442\n",
            "step :  15500 iters_100_time :  37.181615114212036\n",
            "step :  15600 iters_100_time :  123.91336750984192\n",
            "step :  15700 iters_100_time :  124.04250621795654\n",
            "step :  15800 iters_100_time :  124.75933313369751\n",
            "step :  15900 iters_100_time :  123.18203830718994\n",
            "[566/600][442]\n",
            "                    Loss_D: 0.55 Loss_G: 62.76 Time: 548.22s\n",
            "num_batches :  442\n",
            "step :  16000 iters_100_time :  109.39907550811768\n",
            "step :  16100 iters_100_time :  123.94743204116821\n",
            "step :  16200 iters_100_time :  122.9769856929779\n",
            "step :  16300 iters_100_time :  123.75236678123474\n",
            "[567/600][442]\n",
            "                    Loss_D: 0.12 Loss_G: 62.46 Time: 547.23s\n",
            "num_batches :  442\n",
            "step :  16400 iters_100_time :  57.531203508377075\n",
            "step :  16500 iters_100_time :  123.08960843086243\n",
            "step :  16600 iters_100_time :  123.50168085098267\n",
            "step :  16700 iters_100_time :  122.97192978858948\n",
            "[568/600][442]\n",
            "                    Loss_D: 0.10 Loss_G: 58.60 Time: 546.49s\n",
            "num_batches :  442\n",
            "step :  16800 iters_100_time :  5.131375312805176\n",
            "step :  16900 iters_100_time :  124.0017740726471\n",
            "step :  17000 iters_100_time :  122.7522132396698\n",
            "step :  17100 iters_100_time :  124.10715222358704\n",
            "step :  17200 iters_100_time :  123.93548011779785\n",
            "[569/600][442]\n",
            "                    Loss_D: 0.07 Loss_G: 64.91 Time: 547.06s\n",
            "num_batches :  442\n",
            "step :  17300 iters_100_time :  76.73706102371216\n",
            "step :  17400 iters_100_time :  124.10530185699463\n",
            "step :  17500 iters_100_time :  122.8474497795105\n",
            "step :  17600 iters_100_time :  123.64504766464233\n",
            "[570/600][442]\n",
            "                    Loss_D: 0.11 Loss_G: 47.71 Time: 547.14s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  17700 iters_100_time :  25.37136483192444\n",
            "step :  17800 iters_100_time :  123.86404418945312\n",
            "step :  17900 iters_100_time :  122.90329551696777\n",
            "step :  18000 iters_100_time :  123.57570338249207\n",
            "step :  18100 iters_100_time :  123.98740887641907\n",
            "[571/600][442]\n",
            "                    Loss_D: 0.04 Loss_G: 68.09 Time: 547.26s\n",
            "num_batches :  442\n",
            "step :  18200 iters_100_time :  96.98250031471252\n",
            "step :  18300 iters_100_time :  123.86889052391052\n",
            "step :  18400 iters_100_time :  122.96776247024536\n",
            "step :  18500 iters_100_time :  123.5238881111145\n",
            "[572/600][442]\n",
            "                    Loss_D: 0.04 Loss_G: 67.21 Time: 547.40s\n",
            "num_batches :  442\n",
            "step :  18600 iters_100_time :  44.79730772972107\n",
            "step :  18700 iters_100_time :  123.47206974029541\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBwYuwliPq-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}