{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SLGL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWKs7S4PZR2b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "85962683-5528-406d-8db8-6605e0ea9343"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Aug 11 12:09:20 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTzcYrCvZuQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "!rm -r sample_data"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkB9zZRNbw9N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "7092cd71-237b-4574-bbdc-e55744e870f1"
      },
      "source": [
        "#clone repo AttnGAN\n",
        "os.chdir('/content/')\n",
        "!rm -r AttnGAN\n",
        "!git clone https://github.com/taoxugit/AttnGAN.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'AttnGAN': No such file or directory\n",
            "Cloning into 'AttnGAN'...\n",
            "remote: Enumerating objects: 291, done.\u001b[K\n",
            "remote: Total 291 (delta 0), reused 0 (delta 0), pack-reused 291\n",
            "Receiving objects: 100% (291/291), 36.76 MiB | 14.68 MiB/s, done.\n",
            "Resolving deltas: 100% (167/167), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vj7VSMY-c6uI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "e0dc92c2-7ff7-49b0-c6c9-070d68fd57d1"
      },
      "source": [
        "# Download captionts filenames and classes info\n",
        "os.chdir('/content/AttnGAN/data/')\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ' -O birds.zip\n",
        "!unzip -q birds.zip\n",
        "!rm birds.zip\n",
        "!rm -r __MACOSX/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-11 12:09:37--  https://docs.google.com/uc?export=download&id=1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.126.113, 108.177.126.138, 108.177.126.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.126.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0o-9g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/dons8ljjaj788v802876gh70btjufasn/1597147800000/09657060183789739732/*/1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-08-11 12:10:07--  https://doc-0o-9g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/dons8ljjaj788v802876gh70btjufasn/1597147800000/09657060183789739732/*/1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ?e=download\n",
            "Resolving doc-0o-9g-docs.googleusercontent.com (doc-0o-9g-docs.googleusercontent.com)... 74.125.128.132, 2a00:1450:4013:c02::84\n",
            "Connecting to doc-0o-9g-docs.googleusercontent.com (doc-0o-9g-docs.googleusercontent.com)|74.125.128.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘birds.zip’\n",
            "\n",
            "birds.zip               [  <=>               ]   6.19M  27.2MB/s    in 0.2s    \n",
            "\n",
            "2020-08-11 12:10:07 (27.2 MB/s) - ‘birds.zip’ saved [6488322]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDk_GzlMduaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Changing Working dirctory to birds\n",
        "os.chdir('/content/AttnGAN/data/birds/')\n",
        "!cp '/content/drive/My Drive/cub/CUB_200_2011.tgz' '/content/AttnGAN/data/birds/'\n",
        "!tar zxf  CUB_200_2011.tgz\n",
        "!rm CUB_200_2011.tgz"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r3rHv8ycCAS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "e2eeff90-1940-4ee4-dd82-0bb8865c2d46"
      },
      "source": [
        "#Dwonload files text encoder and image encoder\n",
        "os.chdir('/content/AttnGAN/DAMSMencoders/')\n",
        "!rm -r bird/\n",
        "os.mkdir('bird')\n",
        "os.chdir('/content/')\n",
        "!git clone https://github.com/ammarnasr/CUB-Attn-GAN.git\n",
        "\n",
        "# #Move Models text and image encoder to their /content/\n",
        "!mv  /content/CUB-Attn-GAN/theModel/text_encoder599.pth  /content/AttnGAN/DAMSMencoders/bird/\n",
        "!mv /content/CUB-Attn-GAN/theModel/image_encoder599.pth /content/AttnGAN/DAMSMencoders/bird/\n",
        "\n",
        "!rm -r CUB-Attn-GAN "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'bird/': No such file or directory\n",
            "Cloning into 'CUB-Attn-GAN'...\n",
            "remote: Enumerating objects: 292, done.\u001b[K\n",
            "remote: Counting objects: 100% (292/292), done.\u001b[K\n",
            "remote: Compressing objects: 100% (187/187), done.\u001b[K\n",
            "remote: Total 842 (delta 197), reused 193 (delta 103), pack-reused 550\u001b[K\n",
            "Receiving objects: 100% (842/842), 475.00 MiB | 8.81 MiB/s, done.\n",
            "Resolving deltas: 100% (497/497), done.\n",
            "Checking out files: 100% (117/117), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDFg63INfn0O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "e80ccbe8-0a10-49df-a638-4146e2537e52"
      },
      "source": [
        "#Download Pillow Font\n",
        "os.chdir('/content/AttnGAN/code/')\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Wr3lQajG7m6Bi3rYFTJb6mwE_d8su111' -O Pillow.rar\n",
        "!unrar x  Pillow.rar\n",
        "!rm Pillow.rar"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-11 12:12:31--  https://docs.google.com/uc?export=download&id=1Wr3lQajG7m6Bi3rYFTJb6mwE_d8su111\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.127.100, 108.177.127.138, 108.177.127.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.127.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-04-6c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/7bf102rj5b49nbnmdf6gpnpe00et88r9/1597147950000/17309505201871794426/*/1Wr3lQajG7m6Bi3rYFTJb6mwE_d8su111?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-08-11 12:12:32--  https://doc-04-6c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/7bf102rj5b49nbnmdf6gpnpe00et88r9/1597147950000/17309505201871794426/*/1Wr3lQajG7m6Bi3rYFTJb6mwE_d8su111?e=download\n",
            "Resolving doc-04-6c-docs.googleusercontent.com (doc-04-6c-docs.googleusercontent.com)... 74.125.128.132, 2a00:1450:4013:c02::84\n",
            "Connecting to doc-04-6c-docs.googleusercontent.com (doc-04-6c-docs.googleusercontent.com)|74.125.128.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 257793 (252K) [application/x-rar]\n",
            "Saving to: ‘Pillow.rar’\n",
            "\n",
            "Pillow.rar          100%[===================>] 251.75K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2020-08-11 12:12:33 (123 MB/s) - ‘Pillow.rar’ saved [257793/257793]\n",
            "\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from Pillow.rar\n",
            "\n",
            "Creating    Pillow                                                    OK\n",
            "Creating    Pillow/Tests                                              OK\n",
            "Creating    Pillow/Tests/fonts                                        OK\n",
            "Extracting  Pillow/Tests/fonts/FreeMono.ttf                              \b\b\b\b 12%\b\b\b\b 25%\b\b\b\b 38%\b\b\b\b 50%\b\b\b\b 63%\b\b\b\b 76%\b\b\b\b 88%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gTLsxwtly4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Checkpoint from drive, edit in bird_attnGAN2.ymal also\n",
        "!cp '/content/drive/My Drive/ModifiedcubModelGAN/netG_epoch_240.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/ModifiedcubModelGAN/netD0.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/ModifiedcubModelGAN/netD1.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/ModifiedcubModelGAN/netD2.pth' '/content/AttnGAN/models/'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESi47FqIgLlw",
        "colab_type": "text"
      },
      "source": [
        "# =============================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mTJmFZTgLPJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "0160748f-21a1-45db-b6a3-af7929e98edd"
      },
      "source": [
        "#Move code files to their Locations\n",
        "os.chdir('/content')\n",
        "!rm -r SentLevelGANLoss/\n",
        "!git clone https://github.com/ammarnasr/SentLevelGANLoss.git\n",
        "\n",
        "!mv /content/SentLevelGANLoss/theCode/config.py                      /content/AttnGAN/code/miscc/\n",
        "!mv /content/SentLevelGANLoss/theCode/utils.py                      /content/AttnGAN/code/miscc/\n",
        "!mv /content/SentLevelGANLoss/theCode/datasets.py                  /content/AttnGAN/code/\n",
        "!mv /content/SentLevelGANLoss/theCode/GlobalAttention.py          /content/AttnGAN/code/\n",
        "!mv /content/SentLevelGANLoss/theCode/model.py                   /content/AttnGAN/code/\n",
        "!mv /content/SentLevelGANLoss/theCode/losses.py                 /content/AttnGAN/code/miscc/\n",
        "!mv /content/SentLevelGANLoss/theCode/trainer.py               /content/AttnGAN/code/\n",
        "!mv /content/SentLevelGANLoss/theCode/bird_attn2.yml          /content/AttnGAN/code/cfg/"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'SentLevelGANLoss/': No such file or directory\n",
            "Cloning into 'SentLevelGANLoss'...\n",
            "remote: Enumerating objects: 84, done.\u001b[K\n",
            "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 84 (delta 32), reused 71 (delta 22), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (84/84), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btCJ5ibpf7rZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "199fd03d-1b2c-4ac9-956d-87a839fd6279"
      },
      "source": [
        "#run Code\n",
        "os.chdir('/content/AttnGAN/code/')\n",
        "!python main.py --cfg cfg/bird_attn2.yml --gpu 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using config:\n",
            "{'B_VALIDATION': False,\n",
            " 'CONFIG_NAME': 'attn2',\n",
            " 'CUDA': True,\n",
            " 'DATASET_NAME': 'birds',\n",
            " 'DATA_DIR': '../data/birds',\n",
            " 'GAN': {'B_ATTENTION': True,\n",
            "         'B_DCGAN': False,\n",
            "         'CONDITION_DIM': 100,\n",
            "         'DF_DIM': 64,\n",
            "         'GF_DIM': 32,\n",
            "         'R_NUM': 2,\n",
            "         'Z_DIM': 100},\n",
            " 'GPU_ID': 0,\n",
            " 'RNN_TYPE': 'LSTM',\n",
            " 'TEXT': {'CAPTIONS_PER_IMAGE': 10, 'EMBEDDING_DIM': 256, 'WORDS_NUM': 18},\n",
            " 'TRAIN': {'BATCH_SIZE': 20,\n",
            "           'B_NET_D': True,\n",
            "           'DISCRIMINATOR_LR': 0.0002,\n",
            "           'ENCODER_LR': 0.0002,\n",
            "           'FLAG': True,\n",
            "           'GENERATOR_LR': 0.0002,\n",
            "           'MAX_EPOCH': 600,\n",
            "           'NET_E': '../DAMSMencoders/bird/text_encoder599.pth',\n",
            "           'NET_G': '../models/netG_epoch_180.pth',\n",
            "           'RNN_GRAD_CLIP': 0.25,\n",
            "           'SMOOTH': {'GAMMA1': 4.0,\n",
            "                      'GAMMA2': 5.0,\n",
            "                      'GAMMA3': 10.0,\n",
            "                      'LAMBDA': 5.0},\n",
            "           'SNAPSHOT_INTERVAL': 10},\n",
            " 'TREE': {'BASE_SIZE': 64, 'BRANCH_NUM': 3},\n",
            " 'WORKERS': 4}\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:257: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions.pickle\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/models/inception.py:77: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-1a9a5a14.pth\n",
            "100% 104M/104M [00:01<00:00, 80.9MB/s] \n",
            "Load pretrained model from  https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\n",
            "Load image encoder from: ../DAMSMencoders/bird/image_encoder599.pth\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Load text encoder from: ../DAMSMencoders/bird/text_encoder599.pth\n",
            "/content/AttnGAN/code/miscc/utils.py:404: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  nn.init.orthogonal(m.weight.data, 1.0)\n",
            "/content/AttnGAN/code/miscc/utils.py:399: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  nn.init.orthogonal(m.weight.data, 1.0)\n",
            "# of netsD 3\n",
            "Load G from:  ../models/netG_epoch_180.pth\n",
            "Load D from:  ../models/netD0.pth\n",
            "Load D from:  ../models/netD1.pth\n",
            "Load D from:  ../models/netD2.pth\n",
            "START EPOCH IS =========  181\n",
            "num_batches :  442\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/content/AttnGAN/code/GlobalAttention.py:116: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = self.sm(attn)  # Eq. (2)\n",
            "/content/AttnGAN/code/GlobalAttention.py:135: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  sent_att                = nn.Softmax()(sentence_vs)  # batch x idf x ih x iw\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/content/AttnGAN/code/GlobalAttention.py:51: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = nn.Softmax()(attn)  # Eq. (8)\n",
            "/content/AttnGAN/code/GlobalAttention.py:60: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = nn.Softmax()(attn)\n",
            "[W TensorIterator.cpp:918] Warning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (function operator())\n",
            "/content/AttnGAN/code/trainer.py:428: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
            "  avg_p.mul_(0.999).add_(0.001, p.data)\n",
            "step :  100 iters_100_time :  126.61472678184509\n",
            "step :  200 iters_100_time :  122.03928995132446\n",
            "step :  300 iters_100_time :  122.31929135322571\n",
            "step :  400 iters_100_time :  122.16475224494934\n",
            "[181/600][442]\n",
            "                    Loss_D: 0.13 Loss_G: 44.78 Time: 544.69s\n",
            "num_batches :  442\n",
            "step :  500 iters_100_time :  71.17908072471619\n",
            "step :  600 iters_100_time :  122.27032518386841\n",
            "step :  700 iters_100_time :  122.43773651123047\n",
            "step :  800 iters_100_time :  122.36964964866638\n",
            "[182/600][442]\n",
            "                    Loss_D: 0.49 Loss_G: 59.88 Time: 541.47s\n",
            "num_batches :  442\n",
            "step :  900 iters_100_time :  19.97171378135681\n",
            "step :  1000 iters_100_time :  122.43661069869995\n",
            "step :  1100 iters_100_time :  122.30236840248108\n",
            "step :  1200 iters_100_time :  122.46058440208435\n",
            "step :  1300 iters_100_time :  122.34484672546387\n",
            "[183/600][442]\n",
            "                    Loss_D: 0.71 Loss_G: 62.58 Time: 541.69s\n",
            "num_batches :  442\n",
            "step :  1400 iters_100_time :  90.9194872379303\n",
            "step :  1500 iters_100_time :  122.25482773780823\n",
            "step :  1600 iters_100_time :  122.15709400177002\n",
            "step :  1700 iters_100_time :  122.31016826629639\n",
            "[184/600][442]\n",
            "                    Loss_D: 0.55 Loss_G: 54.23 Time: 541.14s\n",
            "num_batches :  442\n",
            "step :  1800 iters_100_time :  39.648569107055664\n",
            "step :  1900 iters_100_time :  122.46220231056213\n",
            "step :  2000 iters_100_time :  122.42274761199951\n",
            "step :  2100 iters_100_time :  122.15968036651611\n",
            "step :  2200 iters_100_time :  122.18346095085144\n",
            "[185/600][442]\n",
            "                    Loss_D: 0.75 Loss_G: 64.48 Time: 541.65s\n",
            "num_batches :  442\n",
            "step :  2300 iters_100_time :  110.58193612098694\n",
            "step :  2400 iters_100_time :  122.08373045921326\n",
            "step :  2500 iters_100_time :  122.40480899810791\n",
            "step :  2600 iters_100_time :  122.20247030258179\n",
            "[186/600][442]\n",
            "                    Loss_D: 0.12 Loss_G: 53.00 Time: 541.14s\n",
            "num_batches :  442\n",
            "step :  2700 iters_100_time :  59.08146595954895\n",
            "step :  2800 iters_100_time :  122.40053653717041\n",
            "step :  2900 iters_100_time :  122.21426105499268\n",
            "step :  3000 iters_100_time :  122.43699264526367\n",
            "[187/600][442]\n",
            "                    Loss_D: 0.14 Loss_G: 53.14 Time: 541.43s\n",
            "num_batches :  442\n",
            "step :  3100 iters_100_time :  7.685707330703735\n",
            "step :  3200 iters_100_time :  122.34904909133911\n",
            "step :  3300 iters_100_time :  122.66165852546692\n",
            "step :  3400 iters_100_time :  122.17589569091797\n",
            "step :  3500 iters_100_time :  122.33447337150574\n",
            "[188/600][442]\n",
            "                    Loss_D: 0.06 Loss_G: 57.34 Time: 541.57s\n",
            "num_batches :  442\n",
            "step :  3600 iters_100_time :  78.60634088516235\n",
            "step :  3700 iters_100_time :  122.0746865272522\n",
            "step :  3800 iters_100_time :  122.14633297920227\n",
            "step :  3900 iters_100_time :  122.58079123497009\n",
            "[189/600][442]\n",
            "                    Loss_D: 0.57 Loss_G: 52.19 Time: 541.26s\n",
            "num_batches :  442\n",
            "step :  4000 iters_100_time :  27.302976369857788\n",
            "step :  4100 iters_100_time :  122.77062320709229\n",
            "step :  4200 iters_100_time :  122.36112022399902\n",
            "step :  4300 iters_100_time :  122.25967073440552\n",
            "step :  4400 iters_100_time :  122.13764715194702\n",
            "[190/600][442]\n",
            "                    Loss_D: 0.61 Loss_G: 40.12 Time: 541.62s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  4500 iters_100_time :  98.3257532119751\n",
            "step :  4600 iters_100_time :  122.12578678131104\n",
            "step :  4700 iters_100_time :  122.17118835449219\n",
            "step :  4800 iters_100_time :  122.40780854225159\n",
            "[191/600][442]\n",
            "                    Loss_D: 0.92 Loss_G: 39.73 Time: 541.34s\n",
            "num_batches :  442\n",
            "step :  4900 iters_100_time :  46.830045223236084\n",
            "step :  5000 iters_100_time :  122.33807182312012\n",
            "step :  5100 iters_100_time :  122.25066781044006\n",
            "step :  5200 iters_100_time :  122.19106912612915\n",
            "step :  5300 iters_100_time :  122.22555351257324\n",
            "[192/600][442]\n",
            "                    Loss_D: 0.42 Loss_G: 39.72 Time: 540.97s\n",
            "num_batches :  442\n",
            "step :  5400 iters_100_time :  117.76530051231384\n",
            "step :  5500 iters_100_time :  122.16837763786316\n",
            "step :  5600 iters_100_time :  122.10614156723022\n",
            "step :  5700 iters_100_time :  122.05604672431946\n",
            "[193/600][442]\n",
            "                    Loss_D: 2.82 Loss_G: 45.58 Time: 540.72s\n",
            "num_batches :  442\n",
            "step :  5800 iters_100_time :  66.45777416229248\n",
            "step :  5900 iters_100_time :  122.35201573371887\n",
            "step :  6000 iters_100_time :  122.42820596694946\n",
            "step :  6100 iters_100_time :  122.20471239089966\n",
            "[194/600][442]\n",
            "                    Loss_D: 1.09 Loss_G: 35.71 Time: 541.65s\n",
            "num_batches :  442\n",
            "step :  6200 iters_100_time :  15.132663249969482\n",
            "step :  6300 iters_100_time :  122.40102958679199\n",
            "step :  6400 iters_100_time :  122.00770330429077\n",
            "step :  6500 iters_100_time :  122.45249032974243\n",
            "step :  6600 iters_100_time :  122.16566634178162\n",
            "[195/600][442]\n",
            "                    Loss_D: 0.64 Loss_G: 51.69 Time: 541.27s\n",
            "num_batches :  442\n",
            "step :  6700 iters_100_time :  85.91260051727295\n",
            "step :  6800 iters_100_time :  122.26207518577576\n",
            "step :  6900 iters_100_time :  122.02440571784973\n",
            "step :  7000 iters_100_time :  122.27776956558228\n",
            "[196/600][442]\n",
            "                    Loss_D: 0.53 Loss_G: 56.10 Time: 540.83s\n",
            "num_batches :  442\n",
            "step :  7100 iters_100_time :  34.588600397109985\n",
            "step :  7200 iters_100_time :  122.413339138031\n",
            "step :  7300 iters_100_time :  122.49044990539551\n",
            "step :  7400 iters_100_time :  122.11013436317444\n",
            "step :  7500 iters_100_time :  122.35798072814941\n",
            "[197/600][442]\n",
            "                    Loss_D: 0.17 Loss_G: 64.90 Time: 541.44s\n",
            "num_batches :  442\n",
            "step :  7600 iters_100_time :  105.46852707862854\n",
            "step :  7700 iters_100_time :  122.12180638313293\n",
            "step :  7800 iters_100_time :  122.36910700798035\n",
            "step :  7900 iters_100_time :  122.30813097953796\n",
            "[198/600][442]\n",
            "                    Loss_D: 2.16 Loss_G: 85.38 Time: 541.15s\n",
            "num_batches :  442\n",
            "step :  8000 iters_100_time :  54.44477820396423\n",
            "step :  8100 iters_100_time :  122.12707591056824\n",
            "step :  8200 iters_100_time :  122.46321558952332\n",
            "step :  8300 iters_100_time :  122.26404047012329\n",
            "[199/600][442]\n",
            "                    Loss_D: 0.44 Loss_G: 55.97 Time: 541.43s\n",
            "num_batches :  442\n",
            "step :  8400 iters_100_time :  2.8139376640319824\n",
            "step :  8500 iters_100_time :  122.40079379081726\n",
            "step :  8600 iters_100_time :  122.03689861297607\n",
            "step :  8700 iters_100_time :  122.32980990409851\n",
            "step :  8800 iters_100_time :  122.13463616371155\n",
            "[200/600][442]\n",
            "                    Loss_D: 0.59 Loss_G: 57.11 Time: 541.18s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  8900 iters_100_time :  73.82843661308289\n",
            "step :  9000 iters_100_time :  122.20172071456909\n",
            "step :  9100 iters_100_time :  122.04531002044678\n",
            "step :  9200 iters_100_time :  121.98572063446045\n",
            "[201/600][442]\n",
            "                    Loss_D: 0.48 Loss_G: 32.93 Time: 540.69s\n",
            "num_batches :  442\n",
            "step :  9300 iters_100_time :  22.524290323257446\n",
            "step :  9400 iters_100_time :  122.17160272598267\n",
            "step :  9500 iters_100_time :  122.44586944580078\n",
            "step :  9600 iters_100_time :  122.0486626625061\n",
            "step :  9700 iters_100_time :  122.30799531936646\n",
            "[202/600][442]\n",
            "                    Loss_D: 2.36 Loss_G: 62.52 Time: 541.39s\n",
            "num_batches :  442\n",
            "step :  9800 iters_100_time :  93.36859250068665\n",
            "step :  9900 iters_100_time :  122.13543367385864\n",
            "step :  10000 iters_100_time :  122.44354510307312\n",
            "step :  10100 iters_100_time :  122.1641116142273\n",
            "[203/600][442]\n",
            "                    Loss_D: 1.40 Loss_G: 82.43 Time: 541.25s\n",
            "num_batches :  442\n",
            "step :  10200 iters_100_time :  41.95130228996277\n",
            "step :  10300 iters_100_time :  122.54292416572571\n",
            "step :  10400 iters_100_time :  122.06751346588135\n",
            "step :  10500 iters_100_time :  122.384530544281\n",
            "step :  10600 iters_100_time :  122.21946573257446\n",
            "[204/600][442]\n",
            "                    Loss_D: 0.05 Loss_G: 58.13 Time: 541.30s\n",
            "num_batches :  442\n",
            "step :  10700 iters_100_time :  113.09315514564514\n",
            "step :  10800 iters_100_time :  122.4942033290863\n",
            "step :  10900 iters_100_time :  122.02612161636353\n",
            "step :  11000 iters_100_time :  122.21415615081787\n",
            "[205/600][442]\n",
            "                    Loss_D: 0.17 Loss_G: 51.90 Time: 541.32s\n",
            "num_batches :  442\n",
            "step :  11100 iters_100_time :  61.474459648132324\n",
            "step :  11200 iters_100_time :  122.33682060241699\n",
            "step :  11300 iters_100_time :  122.58214569091797\n",
            "step :  11400 iters_100_time :  122.18103885650635\n",
            "[206/600][442]\n",
            "                    Loss_D: 0.29 Loss_G: 54.02 Time: 541.47s\n",
            "num_batches :  442\n",
            "step :  11500 iters_100_time :  10.253790855407715\n",
            "step :  11600 iters_100_time :  122.23628091812134\n",
            "step :  11700 iters_100_time :  122.23454451560974\n",
            "step :  11800 iters_100_time :  122.24666786193848\n",
            "step :  11900 iters_100_time :  122.11628413200378\n",
            "[207/600][442]\n",
            "                    Loss_D: 0.64 Loss_G: 44.30 Time: 541.17s\n",
            "num_batches :  442\n",
            "step :  12000 iters_100_time :  81.20446872711182\n",
            "step :  12100 iters_100_time :  122.11044573783875\n",
            "step :  12200 iters_100_time :  122.3395688533783\n",
            "step :  12300 iters_100_time :  122.3556547164917\n",
            "[208/600][442]\n",
            "                    Loss_D: 0.39 Loss_G: 56.06 Time: 541.40s\n",
            "num_batches :  442\n",
            "step :  12400 iters_100_time :  29.748255729675293\n",
            "step :  12500 iters_100_time :  122.49173951148987\n",
            "step :  12600 iters_100_time :  121.97251415252686\n",
            "step :  12700 iters_100_time :  122.25886583328247\n",
            "step :  12800 iters_100_time :  122.1345841884613\n",
            "[209/600][442]\n",
            "                    Loss_D: 0.20 Loss_G: 58.07 Time: 541.03s\n",
            "num_batches :  442\n",
            "step :  12900 iters_100_time :  100.67235660552979\n",
            "step :  13000 iters_100_time :  122.81758666038513\n",
            "step :  13100 iters_100_time :  121.9797534942627\n",
            "step :  13200 iters_100_time :  122.46397185325623\n",
            "[210/600][442]\n",
            "                    Loss_D: 0.25 Loss_G: 54.01 Time: 541.48s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  13300 iters_100_time :  49.79892683029175\n",
            "step :  13400 iters_100_time :  122.31665182113647\n",
            "step :  13500 iters_100_time :  122.43459010124207\n",
            "step :  13600 iters_100_time :  122.13128447532654\n",
            "step :  13700 iters_100_time :  122.28025484085083\n",
            "[211/600][442]\n",
            "                    Loss_D: 0.22 Loss_G: 51.18 Time: 542.00s\n",
            "num_batches :  442\n",
            "step :  13800 iters_100_time :  120.39355754852295\n",
            "step :  13900 iters_100_time :  122.17531681060791\n",
            "step :  14000 iters_100_time :  122.34628653526306\n",
            "step :  14100 iters_100_time :  122.0566029548645\n",
            "[212/600][442]\n",
            "                    Loss_D: 0.15 Loss_G: 50.42 Time: 541.15s\n",
            "num_batches :  442\n",
            "step :  14200 iters_100_time :  68.93481063842773\n",
            "step :  14300 iters_100_time :  122.53825116157532\n",
            "step :  14400 iters_100_time :  122.11611008644104\n",
            "step :  14500 iters_100_time :  122.43191838264465\n",
            "[213/600][442]\n",
            "                    Loss_D: 0.05 Loss_G: 55.53 Time: 541.66s\n",
            "num_batches :  442\n",
            "step :  14600 iters_100_time :  17.530898809432983\n",
            "step :  14700 iters_100_time :  122.1939172744751\n",
            "step :  14800 iters_100_time :  122.46651887893677\n",
            "step :  14900 iters_100_time :  122.36437249183655\n",
            "step :  15000 iters_100_time :  122.46399879455566\n",
            "[214/600][442]\n",
            "                    Loss_D: 0.44 Loss_G: 56.47 Time: 541.66s\n",
            "num_batches :  442\n",
            "step :  15100 iters_100_time :  88.32468843460083\n",
            "step :  15200 iters_100_time :  122.23643088340759\n",
            "step :  15300 iters_100_time :  122.36268138885498\n",
            "step :  15400 iters_100_time :  122.1901171207428\n",
            "[215/600][442]\n",
            "                    Loss_D: 0.19 Loss_G: 51.65 Time: 541.12s\n",
            "num_batches :  442\n",
            "step :  15500 iters_100_time :  37.23826813697815\n",
            "step :  15600 iters_100_time :  122.39516377449036\n",
            "step :  15700 iters_100_time :  122.22072315216064\n",
            "step :  15800 iters_100_time :  122.40450382232666\n",
            "step :  15900 iters_100_time :  122.03633308410645\n",
            "[216/600][442]\n",
            "                    Loss_D: 0.24 Loss_G: 46.22 Time: 541.32s\n",
            "num_batches :  442\n",
            "step :  16000 iters_100_time :  108.17607998847961\n",
            "step :  16100 iters_100_time :  122.19328737258911\n",
            "step :  16200 iters_100_time :  122.55770111083984\n",
            "step :  16300 iters_100_time :  122.27460503578186\n",
            "[217/600][442]\n",
            "                    Loss_D: 0.82 Loss_G: 71.63 Time: 541.78s\n",
            "num_batches :  442\n",
            "step :  16400 iters_100_time :  56.76872229576111\n",
            "step :  16500 iters_100_time :  122.53158068656921\n",
            "step :  16600 iters_100_time :  122.07062697410583\n",
            "step :  16700 iters_100_time :  122.35677909851074\n",
            "[218/600][442]\n",
            "                    Loss_D: 0.05 Loss_G: 43.87 Time: 541.47s\n",
            "num_batches :  442\n",
            "step :  16800 iters_100_time :  5.293593883514404\n",
            "step :  16900 iters_100_time :  122.34561324119568\n",
            "step :  17000 iters_100_time :  122.67573165893555\n",
            "step :  17100 iters_100_time :  122.27656769752502\n",
            "step :  17200 iters_100_time :  122.42468571662903\n",
            "[219/600][442]\n",
            "                    Loss_D: 0.12 Loss_G: 46.84 Time: 541.78s\n",
            "num_batches :  442\n",
            "step :  17300 iters_100_time :  76.33791971206665\n",
            "step :  17400 iters_100_time :  122.2244975566864\n",
            "step :  17500 iters_100_time :  122.62437033653259\n",
            "step :  17600 iters_100_time :  122.04088306427002\n",
            "[220/600][442]\n",
            "                    Loss_D: 1.62 Loss_G: 33.92 Time: 541.68s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  17700 iters_100_time :  24.917933464050293\n",
            "step :  17800 iters_100_time :  122.56246376037598\n",
            "step :  17900 iters_100_time :  122.35586714744568\n",
            "step :  18000 iters_100_time :  122.40174269676208\n",
            "step :  18100 iters_100_time :  121.91289472579956\n",
            "[221/600][442]\n",
            "                    Loss_D: 0.06 Loss_G: 57.99 Time: 541.50s\n",
            "num_batches :  442\n",
            "step :  18200 iters_100_time :  95.77280259132385\n",
            "step :  18300 iters_100_time :  122.42630505561829\n",
            "step :  18400 iters_100_time :  121.97073221206665\n",
            "step :  18500 iters_100_time :  122.53127789497375\n",
            "[222/600][442]\n",
            "                    Loss_D: 0.18 Loss_G: 57.45 Time: 541.25s\n",
            "num_batches :  442\n",
            "step :  18600 iters_100_time :  44.46186947822571\n",
            "step :  18700 iters_100_time :  122.13447976112366\n",
            "step :  18800 iters_100_time :  122.53131341934204\n",
            "step :  18900 iters_100_time :  121.9054765701294\n",
            "step :  19000 iters_100_time :  122.35950994491577\n",
            "[223/600][442]\n",
            "                    Loss_D: 0.13 Loss_G: 62.96 Time: 541.00s\n",
            "num_batches :  442\n",
            "step :  19100 iters_100_time :  115.3329861164093\n",
            "step :  19200 iters_100_time :  122.42742395401001\n",
            "step :  19300 iters_100_time :  122.39246392250061\n",
            "step :  19400 iters_100_time :  122.0645170211792\n",
            "[224/600][442]\n",
            "                    Loss_D: 0.22 Loss_G: 64.03 Time: 541.28s\n",
            "num_batches :  442\n",
            "step :  19500 iters_100_time :  64.1691963672638\n",
            "step :  19600 iters_100_time :  122.13726472854614\n",
            "step :  19700 iters_100_time :  122.19691562652588\n",
            "step :  19800 iters_100_time :  122.23537254333496\n",
            "[225/600][442]\n",
            "                    Loss_D: 0.04 Loss_G: 67.52 Time: 541.46s\n",
            "num_batches :  442\n",
            "step :  19900 iters_100_time :  12.380940675735474\n",
            "step :  20000 iters_100_time :  122.47386384010315\n",
            "step :  20100 iters_100_time :  122.02747988700867\n",
            "step :  20200 iters_100_time :  122.27484440803528\n",
            "step :  20300 iters_100_time :  122.38596081733704\n",
            "[226/600][442]\n",
            "                    Loss_D: 0.43 Loss_G: 50.55 Time: 541.09s\n",
            "num_batches :  442\n",
            "step :  20400 iters_100_time :  83.35230422019958\n",
            "step :  20500 iters_100_time :  122.52469325065613\n",
            "step :  20600 iters_100_time :  122.09630560874939\n",
            "step :  20700 iters_100_time :  122.39330887794495\n",
            "[227/600][442]\n",
            "                    Loss_D: 1.48 Loss_G: 46.96 Time: 541.14s\n",
            "num_batches :  442\n",
            "step :  20800 iters_100_time :  32.06028723716736\n",
            "step :  20900 iters_100_time :  122.38866806030273\n",
            "step :  21000 iters_100_time :  122.66200304031372\n",
            "step :  21100 iters_100_time :  122.13741207122803\n",
            "step :  21200 iters_100_time :  122.25029754638672\n",
            "[228/600][442]\n",
            "                    Loss_D: 0.13 Loss_G: 50.65 Time: 541.48s\n",
            "num_batches :  442\n",
            "step :  21300 iters_100_time :  103.21744894981384\n",
            "step :  21400 iters_100_time :  122.21856331825256\n",
            "step :  21500 iters_100_time :  122.51429772377014\n",
            "step :  21600 iters_100_time :  122.13580107688904\n",
            "[229/600][442]\n",
            "                    Loss_D: 0.21 Loss_G: 57.30 Time: 541.56s\n",
            "num_batches :  442\n",
            "step :  21700 iters_100_time :  51.861801624298096\n",
            "step :  21800 iters_100_time :  122.25476264953613\n",
            "step :  21900 iters_100_time :  122.24432420730591\n",
            "step :  22000 iters_100_time :  122.47886633872986\n",
            "step :  22100 iters_100_time :  122.05121350288391\n",
            "[230/600][442]\n",
            "                    Loss_D: 0.35 Loss_G: 51.68 Time: 541.29s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  22200 iters_100_time :  122.93291115760803\n",
            "step :  22300 iters_100_time :  122.6546938419342\n",
            "step :  22400 iters_100_time :  122.05804252624512\n",
            "step :  22500 iters_100_time :  122.30510425567627\n",
            "[231/600][442]\n",
            "                    Loss_D: 0.06 Loss_G: 54.92 Time: 541.86s\n",
            "num_batches :  442\n",
            "step :  22600 iters_100_time :  71.40561604499817\n",
            "step :  22700 iters_100_time :  122.17192196846008\n",
            "step :  22800 iters_100_time :  122.71377873420715\n",
            "step :  22900 iters_100_time :  122.15143203735352\n",
            "[232/600][442]\n",
            "                    Loss_D: 0.77 Loss_G: 55.24 Time: 541.44s\n",
            "num_batches :  442\n",
            "step :  23000 iters_100_time :  19.96550226211548\n",
            "step :  23100 iters_100_time :  122.23990297317505\n",
            "step :  23200 iters_100_time :  122.36611032485962\n",
            "step :  23300 iters_100_time :  122.55428576469421\n",
            "step :  23400 iters_100_time :  122.01547265052795\n",
            "[233/600][442]\n",
            "                    Loss_D: 0.37 Loss_G: 47.73 Time: 541.33s\n",
            "num_batches :  442\n",
            "step :  23500 iters_100_time :  91.01811957359314\n",
            "step :  23600 iters_100_time :  122.2580292224884\n",
            "step :  23700 iters_100_time :  122.29432415962219\n",
            "step :  23800 iters_100_time :  122.4984803199768\n",
            "[234/600][442]\n",
            "                    Loss_D: 3.80 Loss_G: 38.71 Time: 541.72s\n",
            "num_batches :  442\n",
            "step :  23900 iters_100_time :  39.511324405670166\n",
            "step :  24000 iters_100_time :  122.42552638053894\n",
            "step :  24100 iters_100_time :  122.23268246650696\n",
            "step :  24200 iters_100_time :  122.30748796463013\n",
            "step :  24300 iters_100_time :  122.35902857780457\n",
            "[235/600][442]\n",
            "                    Loss_D: 0.93 Loss_G: 60.32 Time: 541.49s\n",
            "num_batches :  442\n",
            "step :  24400 iters_100_time :  110.65307354927063\n",
            "step :  24500 iters_100_time :  122.50600242614746\n",
            "step :  24600 iters_100_time :  122.20166611671448\n",
            "step :  24700 iters_100_time :  122.19503402709961\n",
            "[236/600][442]\n",
            "                    Loss_D: 0.82 Loss_G: 45.43 Time: 541.48s\n",
            "num_batches :  442\n",
            "step :  24800 iters_100_time :  59.06788635253906\n",
            "step :  24900 iters_100_time :  122.49049687385559\n",
            "step :  25000 iters_100_time :  122.43765616416931\n",
            "step :  25000 iters_5000_time :  303.99622321128845\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  7.113140821456909\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  26.606048345565796\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  198.71904301643372\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "step :  25100 iters_100_time :  376.3323874473572\n",
            "[237/600][442]\n",
            "                    Loss_D: 1.24 Loss_G: 55.87 Time: 795.53s\n",
            "num_batches :  442\n",
            "step :  25200 iters_100_time :  7.666931629180908\n",
            "step :  25300 iters_100_time :  122.40944361686707\n",
            "step :  25400 iters_100_time :  122.1456458568573\n",
            "step :  25500 iters_100_time :  122.3327305316925\n",
            "step :  25600 iters_100_time :  122.3425395488739\n",
            "[238/600][442]\n",
            "                    Loss_D: 0.93 Loss_G: 49.75 Time: 541.39s\n",
            "num_batches :  442\n",
            "step :  25700 iters_100_time :  78.51643133163452\n",
            "step :  25800 iters_100_time :  122.7218427658081\n",
            "step :  25900 iters_100_time :  122.16979837417603\n",
            "step :  26000 iters_100_time :  122.366947889328\n",
            "[239/600][442]\n",
            "                    Loss_D: 2.05 Loss_G: 53.79 Time: 541.85s\n",
            "num_batches :  442\n",
            "step :  26100 iters_100_time :  27.24401569366455\n",
            "step :  26200 iters_100_time :  122.21404075622559\n",
            "step :  26300 iters_100_time :  122.49865770339966\n",
            "step :  26400 iters_100_time :  122.30384063720703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU78aNl1gQdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-fbFB2yZuaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}